{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At Home Solar Charging notebooks: Exploring how EV charging aligns with rooftop solar generation by homes\n",
    "\n",
    "<p>We will be using Pecan Street Inc. data from Dataport to determine how electric vehicle charging aligns with rooftop solar generation.\n",
    "    \n",
    "<br>Data from 24 homes with fairly complete data for the year 2018 is used to explore this question.\n",
    "    \n",
    "<br>\n",
    "Pecans Streets data can be obtained by applying for a dataport account at https://www.dataport.pecanstreet.org.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "import sqlalchemy as sqla\n",
    "import os\n",
    "from config.read_config import get_database_config\n",
    "import numpy as np\n",
    "import sys\n",
    "%matplotlib inline\n",
    "sys.executable  # shows you your path to the python you're using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in db credentials from config/config.txt\n",
    "# * make sure you add those to the config/config.txt file! *\n",
    "\n",
    "database_config = get_database_config(\"./config/config.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our DB connection\n",
    "engine = sqla.create_engine('postgresql://{}:{}@{}:{}/{}'.format(database_config['username'],\n",
    "                                                                     database_config['password'],\n",
    "                                                                     database_config['hostname'],\n",
    "                                                                     database_config['port'],\n",
    "                                                                     database_config['database']\n",
    "                                                                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select a list of Texas homes from dataport metadata having CAR and solar configured and also has data for year 2018.\n",
    "query = \"\"\"select distinct dataid from other_datasets.metadata \n",
    "                                          where car1='yes' and solar='yes' \n",
    "                                          and egauge_1min_min_time < '2018-01-01' \n",
    "                                          and egauge_1min_max_time > '2019-01-01'\n",
    "                                          and state='Texas'\n",
    "                                          and (egauge_1min_data_availability like '100%' \n",
    "                                               or \n",
    "                                               egauge_1min_data_availability like '99%')\n",
    "                                          ;\n",
    "         \"\"\"\n",
    "\n",
    "df = pd.read_sql_query(sqla.text(query), engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab dataids and convert them to a string to put into the SQL query\n",
    "dataids_list = df['dataid'].tolist()\n",
    "print(\"{} dataids selected listed here:\".format(len(dataids_list)))\n",
    "dataids_str = ','.join(list(map(str, dataids_list)))\n",
    "dataids_str\n",
    "dataids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check data completeness for dataids selected from metadata above.\n",
    "\n",
    "query2 = \"\"\"select dataid,count(*) total_rec from electricity.eg_realpower_1min \n",
    "            where dataid in ({})\"\"\".format(dataids_str)\n",
    "query2 = query2 + \"\"\" and localminute >= '2018-01-01' and localminute < '2019-01-01' group by 1\"\"\"\n",
    "\n",
    "df2 = pd.read_sql_query(sqla.text(query2), engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select homes with atleast 90% data availability for year 2018.\n",
    "df2['perc'] = (df2['total_rec']/525600)*100\n",
    "final_dataids = df2[df2['perc'] >= 90]\n",
    "final_dataids['dataid'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull data for homes\n",
    "final_dataids_list = final_dataids['dataid'].tolist()\n",
    "print(\"{} dataids selected listed here:\".format(len(final_dataids_list)))\n",
    "final_dataids_str = ','.join(list(map(str, final_dataids_list)))\n",
    "final_dataids_str\n",
    "final_dataids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fall\n",
    "fall = \"\"\"select localminute::timestamp,car1,solar,grid \n",
    "               from electricity.eg_realpower_1min \n",
    "               where localminute >= '2018-09-01' and localminute <  '2018-12-01' \"\"\"\n",
    "fall = fall + \"\"\"AND dataid in ({})\"\"\".format(final_dataids_str)\n",
    "\n",
    "fall_df = pd.read_sql_query(sqla.text(fall), engine)\n",
    "\n",
    "fall_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spring\n",
    "spring = \"\"\"select localminute::timestamp,car1,solar,grid \n",
    "               from electricity.eg_realpower_1min \n",
    "               where localminute >= '2018-03-01' and localminute <  '2018-06-01' \"\"\"\n",
    "spring = spring + \"\"\"AND dataid in ({})\"\"\".format(final_dataids_str)\n",
    "\n",
    "spring_df = pd.read_sql_query(sqla.text(spring), engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summer\n",
    "summer = \"\"\"select localminute::timestamp,car1,solar,grid \n",
    "               from electricity.eg_realpower_1min \n",
    "               where localminute >= '2018-06-01' and localminute <  '2018-09-01' \"\"\"\n",
    "summer = summer + \"\"\"AND dataid in ({})\"\"\".format(final_dataids_str)\n",
    "\n",
    "# create a dataframe with the data from the sql query\n",
    "summer_df = pd.read_sql_query(sqla.text(summer), engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#winter\n",
    "winter = \"\"\"select localminute::timestamp,car1,solar,grid \n",
    "               from electricity.eg_realpower_1min \n",
    "               where localminute >= '2018-12-01' and localminute <  '2019-03-01' \"\"\"\n",
    "winter = winter + \"\"\"AND dataid in ({})\"\"\".format(final_dataids_str)\n",
    "\n",
    "# create a dataframe with the data from the sql query\n",
    "winter_df = pd.read_sql_query(sqla.text(winter), engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis for summer\n",
    "\n",
    "#replace null with 0's\n",
    "summer_df = summer_df.fillna(0)\n",
    "# convert localminute to pandas daytime type\n",
    "summer_df['datetime'] = pd.to_datetime(summer_df['localminute'])\n",
    "\n",
    "summer_df = summer_df.set_index('datetime')\n",
    "\n",
    "#create hour column\n",
    "summer_df['hr'] = summer_df.index.hour\n",
    "\n",
    "#create new dataframes with solar, car1, and hour column\n",
    "summer_df_new = pd.DataFrame(summer_df, columns = ['solar', 'car1', 'hr'])\n",
    "\n",
    "# group data based on hour and get avg\n",
    "summer_df_grouped = summer_df_new.groupby(['hr']).mean()\n",
    "plot_summer = summer_df_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot summer\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(plot_summer['hr'], plot_summer['car1'], label=\"car1\")\n",
    "plt.plot(plot_summer['hr'], plot_summer['solar'], label=\"solar\")\n",
    "plt.xticks(np.arange(0, 24, 1.0))\n",
    "plt.xlabel('hour')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total car1 usuage powered by solar in summer\n",
    "total_car1_summer = summer_df_new['car1'].sum()\n",
    "solar_car1_summer = summer_df_new.loc[summer_df_new['car1'] < summer_df_new['solar'], 'car1'].sum()\n",
    "\n",
    "car1_powered_by_solar_summer = (solar_car1_summer/total_car1_summer) * 100\n",
    "car1_powered_by_solar_summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis for fall\n",
    "\n",
    "#replace null with 0's\n",
    "fall_df = fall_df.fillna(0)\n",
    "# convert localminute to pandas daytime type\n",
    "fall_df['datetime'] = pd.to_datetime(fall_df['localminute'])\n",
    "\n",
    "fall_df = fall_df.set_index('datetime')\n",
    "\n",
    "#create hour column\n",
    "fall_df['hr'] = fall_df.index.hour\n",
    "\n",
    "#create new dataframes with solar, car1, and hour column\n",
    "fall_df_new = pd.DataFrame(fall_df, columns = ['solar', 'car1', 'hr'])\n",
    "\n",
    "# group data based on hour and get avg\n",
    "fall_df_grouped = fall_df_new.groupby(['hr']).mean()\n",
    "plot_fall = fall_df_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot fall\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(plot_fall['hr'], plot_fall['car1'], label=\"car1\")\n",
    "plt.plot(plot_fall['hr'], plot_fall['solar'], label=\"solar\")\n",
    "plt.xticks(np.arange(0, 24, 1.0))\n",
    "plt.xlabel('hour')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total car1 usuage powered by solar in fall\n",
    "total_car1_fall = fall_df_new['car1'].sum()\n",
    "solar_car1_fall = fall_df_new.loc[fall_df_new['car1'] < fall_df_new['solar'], 'car1'].sum()\n",
    "\n",
    "car1_powered_by_solar_fall = (solar_car1_fall/total_car1_fall) * 100\n",
    "car1_powered_by_solar_fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data analysis for spring\n",
    "\n",
    "#replace null with 0's \n",
    "spring_df = spring_df.fillna(0)\n",
    "\n",
    "\n",
    "# convert localminute to pandas datetime type\n",
    "spring_df['datetime'] = pd.to_datetime(spring_df['localminute'])\n",
    "\n",
    "spring_df = spring_df.set_index('datetime')\n",
    "\n",
    "#create hour column. We will be calculating average hourly load for spring.\n",
    "spring_df['hr'] = spring_df.index.hour\n",
    "\n",
    "#create new dataframes with only solar, car1 and hour column\n",
    "spring_df_new = pd.DataFrame(spring_df, columns = ['solar', 'car1','hr'])\n",
    "\n",
    "#group data based on hour and take avg\n",
    "spring_df_grouped = spring_df_new.groupby(['hr']).mean()\n",
    "plot_spring = spring_df_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot spring\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(plot_spring['hr'],plot_spring['car1'],label=\"car1\")\n",
    "plt.plot(plot_spring['hr'],plot_spring['solar'],label=\"solar\")\n",
    "plt.xticks(np.arange(0, 24, 1.0))\n",
    "plt.xlabel('hour')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total car1 usage powered by PV system in spring\n",
    "total_car1_spring = spring_df_new['car1'].sum()\n",
    "solar_car1_spring = spring_df_new.loc[spring_df_new['car1'] < spring_df_new['solar'], 'car1'].sum()\n",
    "\n",
    "car1_powered_by_solar_spring = (solar_car1_spring/total_car1_spring)*100\n",
    "car1_powered_by_solar_spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data analysis for winter\n",
    "\n",
    "#replace null with 0's \n",
    "winter_df = winter_df.fillna(0)\n",
    "\n",
    "# convert localminute to pandas datetime type\n",
    "winter_df['datetime'] = pd.to_datetime(winter_df['localminute'])\n",
    "\n",
    "winter_df = winter_df.set_index('datetime')\n",
    "\n",
    "#create hour column. We will be calculating average hourly load for winter.\n",
    "winter_df['hr'] = winter_df.index.hour\n",
    "\n",
    "#create new dataframes with only solar, car1 and hour column\n",
    "winter_df_new = pd.DataFrame(winter_df, columns = ['solar', 'car1','hr'])\n",
    "\n",
    "#group data based on hour and take avg\n",
    "winter_df_grouped = winter_df_new.groupby(['hr']).mean()\n",
    "plot_winter = winter_df_grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot winter\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(plot_winter['hr'],plot_winter['car1'],label=\"car1\")\n",
    "plt.plot(plot_winter['hr'],plot_winter['solar'],label=\"solar\")\n",
    "plt.xticks(np.arange(0, 24, 1.0))\n",
    "plt.xlabel('hour')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total car1 usage powered by PV system in winter\n",
    "total_car1_winter = winter_df_new['car1'].sum()\n",
    "solar_car1_winter = winter_df_new.loc[winter_df_new['car1'] < winter_df_new['solar'], 'car1'].sum()\n",
    "\n",
    "car1_powered_by_solar_winter = (solar_car1_winter/total_car1_winter) * 100\n",
    "car1_powered_by_solar_winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "statistics.mean([car1_powered_by_solar_winter, car1_powered_by_solar_spring, car1_powered_by_solar_summer, car1_powered_by_solar_fall])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "From the above graphs through out the year most homes started EV charging arount 9PM to 9:30PM and ended charging around 6AM (outside of solar peak hours). The average percentage of solar powered used for EV charging is around 4.4 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
