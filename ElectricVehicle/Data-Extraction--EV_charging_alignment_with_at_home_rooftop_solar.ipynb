{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataport Database Extration for: Exploring how EV charging aligns with rooftop solar generation by homes\n",
    "\n",
    "## This notebook will connect to the database and extract the data live and put it into compressed zip files in this directory. \n",
    "\n",
    "\n",
    "<p>We will be using Pecan Street Inc. data from Dataport to determine how electric vehicle charging aligns with rooftop solar generation.\n",
    "    \n",
    "<br>Data from 24 homes with fairly complete data for the year 2018 is used to explore this question.\n",
    "    \n",
    "<br>\n",
    "Pecans Streets data can be obtained by applying for a dataport account at https://www.dataport.pecanstreet.org.</p>\n",
    "\n",
    "<br>\n",
    "You'll need to modify the read_csv calls in that notebook to point at these instead of the ones we've extracted and prepared for you in the /shared/JupyterHub-Examples-Data/ directory on the JupyterHub server if you would like to use the ones exported by this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "import sqlalchemy as sqla\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from config.read_config import get_database_config\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "sys.executable  # shows you your path to the python you're using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in db credentials from ../config/config.txt\n",
    "# * make sure you add those to the ../config/config.txt file! *\n",
    "\n",
    "database_config = get_database_config(\"../config/config.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our DB connection\n",
    "engine = sqla.create_engine('postgresql://{}:{}@{}:{}/{}'.format(database_config['username'],\n",
    "                                                                     database_config['password'],\n",
    "                                                                     database_config['hostname'],\n",
    "                                                                     database_config['port'],\n",
    "                                                                     database_config['database']\n",
    "                                                                     ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select a list of Texas homes from dataport metadata having CAR and solar configured and also has data for year 2018.\n",
    "\n",
    "query = \"\"\"select distinct dataid from other_datasets.metadata \n",
    "                                          where car1='yes' and solar='yes' \n",
    "                                          and egauge_1min_min_time < '2018-01-01' \n",
    "                                          and egauge_1min_max_time > '2019-01-01'\n",
    "                                          and state='Texas'\n",
    "                                          and (egauge_1min_data_availability like '100%' \n",
    "                                               or \n",
    "                                               egauge_1min_data_availability like '99%')\n",
    "                                          LIMIT 25\n",
    "                                          ;\n",
    "         \"\"\"\n",
    "\n",
    "df = pd.read_sql_query(sqla.text(query), engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab dataids and convert them to a string to put into the SQL query\n",
    "dataids_list = df['dataid'].tolist()\n",
    "print(\"{} dataids selected listed here:\".format(len(dataids_list)))\n",
    "dataids_str = ','.join(list(map(str, dataids_list)))\n",
    "dataids_str\n",
    "dataids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check data completeness for dataids selected from metadata above.\n",
    "\n",
    "query2 = \"\"\"select dataid,count(*) total_rec from electricity.eg_realpower_1min \n",
    "            where dataid in ({})\"\"\".format(dataids_str)\n",
    "query2 = query2 + \"\"\" and localminute >= '2018-01-01' and localminute < '2019-01-01' group by 1\"\"\"\n",
    "\n",
    "df2 = pd.read_sql_query(sqla.text(query2), engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select homes with atleast 90% data availability for year 2018.\n",
    "df2['perc'] = (df2['total_rec']/525600)*100\n",
    "final_dataids = df2[df2['perc'] >= 90]\n",
    "final_dataids['dataid'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull data for homes\n",
    "final_dataids_list = final_dataids['dataid'].tolist()\n",
    "print(\"{} dataids selected listed here:\".format(len(final_dataids_list)))\n",
    "final_dataids_str = ','.join(list(map(str, final_dataids_list)))\n",
    "final_dataids_str\n",
    "final_dataids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fall\n",
    "fall = \"\"\"select localminute::timestamp,car1,solar,grid \n",
    "               from electricity.eg_realpower_1min \n",
    "               where localminute >= '2018-09-01' and localminute <  '2018-12-01' \"\"\"\n",
    "fall = fall + \"\"\"AND dataid in ({})\"\"\".format(final_dataids_str)\n",
    "\n",
    "fall_df = pd.read_sql_query(sqla.text(fall), engine)\n",
    "\n",
    "fall_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export fall to a zipped csv\n",
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='ev_charging_alignmnent_fall.csv')\n",
    "fall_df.to_csv('ev_charging_alignmnent_fall.zip', index=False,\n",
    "          compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spring\n",
    "spring = \"\"\"select localminute::timestamp,car1,solar,grid \n",
    "               from electricity.eg_realpower_1min \n",
    "               where localminute >= '2018-03-01' and localminute <  '2018-06-01' \"\"\"\n",
    "spring = spring + \"\"\"AND dataid in ({})\"\"\".format(final_dataids_str)\n",
    "\n",
    "spring_df = pd.read_sql_query(sqla.text(spring), engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export spring to a zipped csv\n",
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='ev_charging_alignmnent_spring.csv')\n",
    "spring_df.to_csv('ev_charging_alignmnent_spring.zip', index=False,\n",
    "          compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summer\n",
    "summer = \"\"\"select localminute::timestamp,car1,solar,grid \n",
    "               from electricity.eg_realpower_1min \n",
    "               where localminute >= '2018-06-01' and localminute <  '2018-09-01' \"\"\"\n",
    "summer = summer + \"\"\"AND dataid in ({})\"\"\".format(final_dataids_str)\n",
    "\n",
    "# create a dataframe with the data from the sql query\n",
    "summer_df = pd.read_sql_query(sqla.text(summer), engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export summer to a zipped csv\n",
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='ev_charging_alignmnent_summer.csv')\n",
    "summer_df.to_csv('ev_charging_alignmnent_summer.zip', index=False,\n",
    "          compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#winter\n",
    "winter = \"\"\"select localminute::timestamp,car1,solar,grid \n",
    "               from electricity.eg_realpower_1min \n",
    "               where localminute >= '2018-12-01' and localminute <  '2019-03-01' \"\"\"\n",
    "winter = winter + \"\"\"AND dataid in ({})\"\"\".format(final_dataids_str)\n",
    "\n",
    "# create a dataframe with the data from the sql query\n",
    "winter_df = pd.read_sql_query(sqla.text(winter), engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export winter to a zipped csv\n",
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='ev_charging_alignmnent_winter.csv')\n",
    "winter_df.to_csv('ev_charging_alignmnent_winter.zip', index=False,\n",
    "          compression=compression_opts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
