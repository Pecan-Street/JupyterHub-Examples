{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataport Database Extration for Overall Energy Demand Notebook: Exploring how a homes overall energy demand is attributable to at-home EV charging\n",
    "\n",
    "## This notebook will connect to the database and extract the data live and put it into compressed zip files in this directory. \n",
    "\n",
    "<p>We will be using Pecan Street Inc. data from dataport to calculate how much overall energy demand is used in homes by electric vehicle charging.<br><br>\n",
    "Pecans Streets data can be obtained by applying for a dataport account at https://www.dataport.pecanstreet.org.</p>\n",
    "\n",
    "<p>You'll need to modify the read_csv calls in that notebook to point at these instead of the ones we've extracted and prepared for you in the /shared/JupyterHub-Examples-Data/ directory on the JupyterHub server if you would like to use the ones exported by this notebook in the analysis notebook.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import sqlalchemy as sqla\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from config.read_config import get_database_config\n",
    "%matplotlib inline\n",
    "sys.executable  # shows you your path to the python you're using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in db credentials from config/config.txt\n",
    "# * make sure you add those to the config/config.txt file! *\n",
    "\n",
    "database_config = get_database_config(\"../config/config.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our DB connection\n",
    "engine = sqla.create_engine('postgresql://{}:{}@{}:{}/{}'.format(database_config['username'],\n",
    "                                                                     database_config['password'],\n",
    "                                                                     database_config['hostname'],\n",
    "                                                                     database_config['port'],\n",
    "                                                                     database_config['database']\n",
    "                                                                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a list of Texas homes from dataport metadata having an electrical vehicle (car1) and also has data for year 2018.\n",
    "query = \"\"\"select distinct dataid from other_datasets.metadata \n",
    "                                          where car1='yes' and grid='yes'\n",
    "                                          and egauge_1min_min_time < '2018-01-01' \n",
    "                                          and egauge_1min_max_time > '2019-01-01'\n",
    "                                          and state='Texas'\n",
    "                                          and (egauge_1min_data_availability like '100%' \n",
    "                                               or \n",
    "                                               egauge_1min_data_availability like '99%')\n",
    "                                               LIMIT 25;\n",
    "         \"\"\"\n",
    "\n",
    "df = pd.read_sql_query(sqla.text(query), engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab dataids and convert them to a string to put into the SQL query\n",
    "dataids_list = df['dataid'].tolist()\n",
    "print(\"{} dataids selected listed here:\".format(len(dataids_list)))\n",
    "dataids_str = ','.join(list(map(str, dataids_list)))\n",
    "dataids_str\n",
    "dataids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data completeness for dataids selected from metadata above.\n",
    "## Warning: This query takes some time to run.\n",
    "query2 = \"\"\"select dataid,count(*) total_rec from electricity.eg_realpower_1min \n",
    "            where dataid in ({})\"\"\".format(dataids_str)\n",
    "query2 = query2 + \"\"\" and localminute >= '2018-01-01' and localminute < '2019-01-01' group by 1\"\"\"\n",
    "\n",
    "df2 = pd.read_sql_query(sqla.text(query2), engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select homes with atleast 99% data availability for year 2018.\n",
    "df2['perc'] = (df2['total_rec']/525600)*100\n",
    "final_dataids = df2[df2['perc'] >= 99]\n",
    "final_dataids['dataid'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble list of selected homes\n",
    "final_dataids_list = final_dataids['dataid'].tolist()\n",
    "print(\"{} dataids selected listed here:\".format(len(final_dataids_list)))\n",
    "final_dataids_str = ','.join(list(map(str, final_dataids_list)))\n",
    "final_dataids_str\n",
    "final_dataids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now go pull the data for the selected homes\n",
    "data_pull = \"\"\"select localminute::timestamp,car1,grid,solar \n",
    "               from electricity.eg_realpower_1min \n",
    "               where localminute >= '2018-03-01' and localminute <  '2018-06-01' \"\"\"\n",
    "data_pull = data_pull + \"\"\"AND dataid in ({})\"\"\".format(final_dataids_str)\n",
    "\n",
    "data_df = pd.read_sql_query(sqla.text(data_pull), engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the data to a csv file\n",
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='ev_overall_household_demand.zip')\n",
    "data_df.to_csv('ev_overall_household_demand.zip', index=False,\n",
    "          compression=compression_opts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
