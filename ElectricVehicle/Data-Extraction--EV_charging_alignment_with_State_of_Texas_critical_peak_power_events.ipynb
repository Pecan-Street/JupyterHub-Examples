{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction for Critical Peak Power Events Notebooks: Exploring how EV charging aligns with Texas's critical peak power events by homes\n",
    "\n",
    "## This notebook will connect to the database and extract the data live and put it into compressed zip files in this directory. \n",
    "\n",
    "<p>We will be using data from ERCOT's 4CP calculations to determine how residential homes EV charging habits align with those Peak power events.<br><br>\n",
    "ERCOT 4CP data is pulled from http://mis.ercot.com/misapp/GetReports.do?reportTypeId=13037&reportTitle=Planned%20Service%20Four%20Coincident%20Peak%20Calculations&showHTMLView=&mimicKey</p>\n",
    "\n",
    "<br>\n",
    "You'll need to modify the read_csv calls in that notebook to point at these instead of the ones we've extracted and prepared for you in the /shared/JupyterHub-Examples-Data/ directory on the JupyterHub server if you would like to use the ones exported by this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "import sqlalchemy as sqla\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from config.read_config import get_database_config\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "sys.executable  # shows you your path to the python you're using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in db credentials from config/config.txt\n",
    "# * make sure you add those to the config/config.txt file! *\n",
    "\n",
    "database_config = get_database_config(\"../config/config.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our DB connection\n",
    "engine = sqla.create_engine('postgresql://{}:{}@{}:{}/{}'.format(database_config['username'],\n",
    "                                                                     database_config['password'],\n",
    "                                                                     database_config['hostname'],\n",
    "                                                                     database_config['port'],\n",
    "                                                                     database_config['database']\n",
    "                                                                     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the ERCOT 4CP events for 2016 - 2019 acquired from\n",
    "# http://mis.ercot.com/misapp/GetReports.do?reportTypeId=13037&reportTitle=Planned%20Service%20Four%20Coincident%20Peak%20Calculations&showHTMLView=&mimicKey\n",
    "\n",
    "event_start_dates = ['2019-06-19 17:00:00-05', '2019-07-30 16:30:00-05', '2019-08-12 17:00:00-05', '2019-09-06 16:45:00-05',\n",
    "               '2018-06-27 17:00:00-05', '2018-07-19 17:00:00-05', '2018-08-23 16:45:00-05', '2018-09-19 16:30:00-05',\n",
    "               '2017-06-23 16:45:00-05', '2017-07-28 17:00:00-05', '2017-08-16 17:00:00-05', '2017-09-20 16:45:00-05',\n",
    "               '2016-06-15 17:00:00-05', '2016-07-14 16:00:00-05', '2016-08-11 16:30:00-05', '2016-09-19 16:15:00-05'\n",
    "              ]\n",
    "event_end_dates = ['2019-06-19 17:15:00-05', '2019-07-30 16:45:00-05', '2019-08-12 17:15:00-05', '2019-09-06 17:00:00-05',\n",
    "               '2018-06-27 17:15:00-05', '2018-07-19 17:15:00-05', '2018-08-23 17:00:00-05', '2018-09-19 16:45:00-05',\n",
    "               '2017-06-23 17:00:00-05', '2017-07-28 17:15:00-05', '2017-08-16 17:15:00-05', '2017-09-20 17:00:00-05',\n",
    "               '2016-06-15 17:15:00-05', '2016-07-14 16:15:00-05', '2016-08-11 16:45:00-05', '2016-09-19 16:30:00-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "\n",
    "query = \"\"\"select dataid, car1 from other_datasets.metadata \n",
    "where car1 is not null \n",
    "and grid is not null\n",
    "and egauge_1min_min_time < '2016-06-15'\n",
    "and egauge_1min_max_time > '2019-09-06'\n",
    "LIMIT 25\n",
    "\"\"\"\n",
    "\n",
    "# create a dataframe with the data from the sql query\n",
    "df = pd.read_sql_query(sqla.text(query), engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab dataids and convert them to a string to put into the SQL Query\n",
    "dataids_list = df['dataid'].tolist()\n",
    "dataids_list\n",
    "print(\"{} dataids selected listed here:\".format(len(dataids_list)))\n",
    "dataids_str = ','.join(list(map(str, dataids_list)))\n",
    "dataids_str\n",
    "dataids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the SQL query to pull the data for the selected dataids\n",
    "\n",
    "first_start = event_start_dates.pop(0)\n",
    "first_end = event_end_dates.pop(0)\n",
    "query_2 = \"\"\"\n",
    "SELECT dataid, localminute, car1, solar, grid FROM electricity.eg_realpower_1min\n",
    "WHERE ((localminute >= '{}' AND localminute <= '{}') \"\"\".format(first_start, first_end)\n",
    "\n",
    "for start, end in zip(event_start_dates, event_end_dates):\n",
    "    query_2 =  query_2 + \"OR (localminute >= '{}' AND localminute <= '{}') \".format(start, end)\n",
    "    \n",
    "query_2 = query_2 + \"\"\" ) AND dataid in ({})\"\"\".format(dataids_str)\n",
    "\n",
    "# here's what that query is\n",
    "print(\"sql query is \\n\" + query_2)\n",
    "\n",
    "# create a dataframe with the data from the sql query\n",
    "df2 = pd.read_sql_query(sqla.text(query_2), engine)\n",
    "\n",
    "\n",
    "df2.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the data to a csv file\n",
    "# export fall to a zipped csv\n",
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='ev_charging_alignmnent_tx_4cp_events.csv')\n",
    "df2.to_csv('ev_charging_alignmnent_tx_4cp_events.zip', index=False,\n",
    "          compression=compression_opts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
