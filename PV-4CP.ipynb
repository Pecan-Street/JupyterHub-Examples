{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PV Notebook\n",
    "This notebook will explore solar generation around the ERCOT 4CP events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "import sqlalchemy as sqla\n",
    "import os\n",
    "from config.read_config import get_database_config\n",
    "import sys\n",
    "sys.executable  # shows you your path to the python you're using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in db credentials from config/config.txt\n",
    "# * make sure you add those to the config/config.txt file! *\n",
    "\n",
    "database_config = get_database_config(\"./config/config.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our DB connection\n",
    "engine = sqla.create_engine('postgresql://{}:{}@{}:{}/{}'.format(database_config['username'],\n",
    "                                                                     database_config['password'],\n",
    "                                                                     database_config['hostname'],\n",
    "                                                                     database_config['port'],\n",
    "                                                                     database_config['database']\n",
    "                                                                     ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the ERCOT 4CP events for 2016 - 2019 acquired from\n",
    "# http://mis.ercot.com/misapp/GetReports.do?reportTypeId=13037&reportTitle=Planned%20Service%20Four%20Coincident%20Peak%20Calculations&showHTMLView=&mimicKey\n",
    "\n",
    "event_start_dates = ['2019-06-19 17:00:00-05', '2019-07-30 16:30:00-05', '2019-08-12 17:00:00-05', '2019-09-06 16:45:00-05',\n",
    "               '2018-06-27 17:00:00-05', '2018-07-19 17:00:00-05', '2018-08-23 16:45:00-05', '2018-09-19 16:30:00-05',\n",
    "               '2017-06-23 16:45:00-05', '2017-07-28 17:00:00-05', '2017-08-16 17:00:00-05', '2017-09-20 16:45:00-05',\n",
    "               '2016-06-15 17:00:00-05', '2016-07-14 16:00:00-05', '2016-08-11 16:30:00-05', '2016-09-19 16:16:00-05'\n",
    "              ]\n",
    "event_end_dates = ['2019-06-19 17:15:00-05', '2019-07-30 16:45:00-05', '2019-08-12 17:15:00-05', '2019-09-06 17:00:00-05',\n",
    "               '2018-06-27 17:15:00-05', '2018-07-19 17:15:00-05', '2018-08-23 17:00:00-05', '2018-09-19 16:45:00-05',\n",
    "               '2017-06-23 17:00:00-05', '2017-07-28 17:15:00-05', '2017-08-16 17:15:00-05', '2017-09-20 17:00:00-05',\n",
    "               '2016-06-15 17:15:00-05', '2016-07-14 16:15:00-05', '2016-08-11 16:45:00-05', '2016-09-19 16:31:00-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the dataids, pv direction, amount of PV of solar homes\n",
    "# we're selecting homes with just South and West facing PV that have data between the first event and the last event\n",
    "\n",
    "###### AAAAAH I should probably check on 1 min availabililty percentange here as well.\n",
    "##### TODO!\n",
    "\n",
    "query = \"\"\"\n",
    "select dataid, pv, pv_panel_direction, total_amount_of_pv, amount_of_west_facing_pv, amount_of_south_facing_pv\n",
    "from other_datasets.metadata\n",
    "where pv is not null\n",
    "and total_amount_of_pv is not null\n",
    "and grid is not null \n",
    "and solar is not null\n",
    "and pv_panel_direction in ('South', 'West')\n",
    "and egauge_1min_min_time < '2016-06-15'\n",
    "and egauge_1min_max_time > '2019-09-06'\n",
    "and (egauge_1min_data_availability = '100%'\n",
    "OR egauge_1min_data_availability = '99%'\n",
    "OR egauge_1min_data_availability = '98%'\n",
    "OR egauge_1min_data_availability = '97%'\n",
    "\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# create a dataframe with the data from the sql query\n",
    "df = pd.read_sql_query(sqla.text(query), engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab dataids and convert them to a string to put into the SQL query\n",
    "dataids_list = df['dataid'].tolist()\n",
    "dataids_list\n",
    "print(\"{} dataids selected listed here:\".format(len(dataids_list)))\n",
    "dataids_str = ','.join(list(map(str, dataids_list)))\n",
    "dataids_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the SQL query to pull the data for the selected dataids\n",
    "# \n",
    "first_start = event_start_dates.pop(0)\n",
    "first_end   = event_end_dates.pop(0)\n",
    "query_2 = \"\"\"\n",
    "select dataid, localminute, solar, grid from electricity.eg_realpower_1min \n",
    "where ((localminute >= '{}' and localminute <= '{}') \"\"\".format(first_start, first_end)\n",
    "\n",
    "for start, end in zip(event_start_dates, event_end_dates):\n",
    "    query_2 = query_2 + \"OR (localminute >= '{}' and localminute <= '{}') \".format(start, end)\n",
    "\n",
    "query_2 = query_2 + \"\"\" ) AND dataid in ({})\"\"\".format(dataids_str)\n",
    "\n",
    "# here's what that query is\n",
    "print(\"sql query is \\n\" + query_2)\n",
    "\n",
    "# create a dataframe with the data from the sql query\n",
    "df2 = pd.read_sql_query(sqla.text(query_2), engine)\n",
    "\n",
    "# calculate usage as grid minus solar (which is actually grid + solar because solar is negative use)\n",
    "# Calculate the difference with a lambda function and add it as a new column called 'usage'\n",
    "df2['usage'] = df2.apply(lambda row: row.solar + row.grid, axis=1)\n",
    "df2.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert localminute to pandas datetime type\n",
    "df2['datetime'] = pd.to_datetime(df2['localminute'])\n",
    "\n",
    "# and set as index\n",
    "df2 = df2.set_index('datetime')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by month and dataid and take the mean of solar, grid, and usage within those groups\n",
    "grouped = df2.groupby([pd.Grouper(freq='M'), 'dataid']).mean()\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map pv direction onto dataids with a merge after resetting the index\n",
    "grouped = grouped.reset_index()\n",
    "grouped = grouped.merge(df, how='left', left_on='dataid', right_on='dataid')\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex by the date\n",
    "grouped = grouped.set_index('datetime')\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regroup by year and pv_panel_direction and average the values\n",
    "year_west_vs_south = (grouped.groupby([pd.Grouper(freq='Y'),'pv_panel_direction']).mean())\n",
    "# we don't need a mean of the dataids, so we can drop that column now\n",
    "year_west_vs_south = year_west_vs_south.drop(columns=['dataid'])\n",
    "year_west_vs_south"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# despite the higher in-home usage in the west facing houses (usage) the solar production is so high that it is still putting power back on the grid (grid is smaller or even negative in most cases in West facing homes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now just drop unneeded columns and rearrange them and simplify the view\n",
    "year_west_vs_south = year_west_vs_south.reset_index()\n",
    "year_west_vs_south['year'] = pd.DatetimeIndex(year_west_vs_south['datetime']).year\n",
    "year_west_vs_south = year_west_vs_south[['year', 'pv_panel_direction','solar', 'grid', 'usage']]\n",
    "year_west_vs_south = year_west_vs_south.set_index('year')\n",
    "year_west_vs_south"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "plot = year_west_vs_south.plot(kind='bar',figsize=(25,15), title=\"Solar production, Net Grid Usage (home usage from the grid minus solar production), and Home Usage During ERCOT 4CP events\")\n",
    "labels = plot.set_xticklabels(['2016-S', '2016-W', '2017-S', '2017-W', '2018-S', '2018-W', '2019-S', '2019-W'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
