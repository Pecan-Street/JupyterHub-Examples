{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction Notebook for PV: Solar production on south- vs. west-facing rooftop and how solar systems align with 4CP events in Texas\n",
    "\n",
    "## This notebook will connect to the database and extract the data live and put it into compressed zip files in this directory. \n",
    "\n",
    "This notebook will explore solar generation around the ERCOT 4CP events and compare West vs South facing solar generation during those events.\n",
    "\n",
    "The ERCOT 4CP events are the 15-minute ERCOT grid peak events for each month in June, July, August and September.\n",
    "\n",
    "ERCOT uses each large customerâ€™s (including municipal utilities) total energy demand during the 4CP periods in the previous year as the basis for charges in the current year.\n",
    "\n",
    "<p>You'll need to modify the read_csv calls in that notebook to point at these instead of the ones we've extracted and prepared for you in the /shared/JupyterHub-Examples-Data/ directory on the JupyterHub server if you would like to use the ones exported by this notebook in the analysis notebook.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import sqlalchemy as sqla\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from config.read_config import get_database_config\n",
    "%matplotlib inline\n",
    "sys.executable  # shows you your path to the python you're using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in db credentials from config/config.txt\n",
    "# * make sure you add those to the config/config.txt file! *\n",
    "\n",
    "database_config = get_database_config(\"../config/config.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our DB connection\n",
    "engine = sqla.create_engine('postgresql://{}:{}@{}:{}/{}'.format(database_config['username'],\n",
    "                                                                     database_config['password'],\n",
    "                                                                     database_config['hostname'],\n",
    "                                                                     database_config['port'],\n",
    "                                                                     database_config['database']\n",
    "                                                                     ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the ERCOT 4CP events (start date/time and end date/time) for 2016 - 2019 acquired from\n",
    "# http://mis.ercot.com/misapp/GetReports.do?reportTypeId=13037&reportTitle=Planned%20Service%20Four%20Coincident%20Peak%20Calculations&showHTMLView=&mimicKey\n",
    "\n",
    "event_start_dates = ['2019-06-19 17:00:00-05', '2019-07-30 16:30:00-05', '2019-08-12 17:00:00-05', '2019-09-06 16:45:00-05',\n",
    "               '2018-06-27 17:00:00-05', '2018-07-19 17:00:00-05', '2018-08-23 16:45:00-05', '2018-09-19 16:30:00-05',\n",
    "               '2017-06-23 16:45:00-05', '2017-07-28 17:00:00-05', '2017-08-16 17:00:00-05', '2017-09-20 16:45:00-05',\n",
    "               '2016-06-15 17:00:00-05', '2016-07-14 16:00:00-05', '2016-08-11 16:30:00-05', '2016-09-19 16:16:00-05'\n",
    "              ]\n",
    "event_end_dates = ['2019-06-19 17:15:00-05', '2019-07-30 16:45:00-05', '2019-08-12 17:15:00-05', '2019-09-06 17:00:00-05',\n",
    "               '2018-06-27 17:15:00-05', '2018-07-19 17:15:00-05', '2018-08-23 17:00:00-05', '2018-09-19 16:45:00-05',\n",
    "               '2017-06-23 17:00:00-05', '2017-07-28 17:15:00-05', '2017-08-16 17:15:00-05', '2017-09-20 17:00:00-05',\n",
    "               '2016-06-15 17:15:00-05', '2016-07-14 16:15:00-05', '2016-08-11 16:45:00-05', '2016-09-19 16:31:00-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the dataids, pv direction, amount of PV of solar homes\n",
    "# we're selecting homes with just South and West facing PV that have data between the first event and the last event\n",
    "\n",
    "\n",
    "query = \"\"\"\n",
    "select dataid, pv, pv_panel_direction, total_amount_of_pv, amount_of_west_facing_pv, amount_of_south_facing_pv\n",
    "from other_datasets.metadata\n",
    "where pv is not null\n",
    "and total_amount_of_pv is not null\n",
    "and grid is not null \n",
    "and solar is not null\n",
    "and pv_panel_direction in ('South', 'West')\n",
    "and egauge_1min_min_time < '2016-06-15'\n",
    "and egauge_1min_max_time > '2019-09-06'\n",
    "LIMIT 32\n",
    "\"\"\"\n",
    "\n",
    "# create a Pandas dataframe with the data from the sql query\n",
    "df = pd.read_sql_query(sqla.text(query), engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export homes to csv file\n",
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='pv_south_vs_west_homes.zip')\n",
    "df.to_csv('pv_south_vs_west_homes.zip', index=False,\n",
    "          compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab dataids and convert them to a string to put into the SQL query\n",
    "dataids_list = df['dataid'].tolist()\n",
    "print(\"{} dataids selected listed here:\".format(len(dataids_list)))\n",
    "dataids_str = ','.join(list(map(str, dataids_list)))\n",
    "dataids_str\n",
    "dataids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the SQL query to pull the data for the selected dataids\n",
    "# \n",
    "first_start = event_start_dates.pop(0)\n",
    "first_end   = event_end_dates.pop(0)\n",
    "query_2 = \"\"\"\n",
    "select dataid, localminute, solar, grid from electricity.eg_realpower_1min \n",
    "where ((localminute >= '{}' and localminute <= '{}') \"\"\".format(first_start, first_end)\n",
    "\n",
    "for start, end in zip(event_start_dates, event_end_dates):\n",
    "    query_2 = query_2 + \"OR (localminute >= '{}' and localminute <= '{}') \".format(start, end)\n",
    "\n",
    "query_2 = query_2 + \"\"\" ) AND dataid in ({})\"\"\".format(dataids_str)\n",
    "\n",
    "# here's what that query is\n",
    "print(\"sql query is \\n\" + query_2)\n",
    "\n",
    "# create a dataframe with the data from the sql query\n",
    "df2 = pd.read_sql_query(sqla.text(query_2), engine)\n",
    "\n",
    "# calculate usage as grid minus solar (which is actually grid + solar because solar is negative use)\n",
    "# Calculate the difference with a lambda function and add it as a new column called 'usage'\n",
    "df2['usage'] = df2.apply(lambda row: row.solar + row.grid, axis=1)\n",
    "df2.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of records in the dataset\n",
    "df2['dataid'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the data to a csv file\n",
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='pv_south_vs_west.zip')\n",
    "df2.to_csv('pv_south_vs_west.zip', index=False,\n",
    "          compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
